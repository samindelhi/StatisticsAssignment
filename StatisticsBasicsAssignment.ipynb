{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wsG14NjV6orM",
        "1kXex3dE6z-w"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Assignment\n",
        "---"
      ],
      "metadata": {
        "id": "0cjcm5M-6N_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical Questions\n",
        "---"
      ],
      "metadata": {
        "id": "wsG14NjV6orM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory Questions & Answers\n",
        "---\n",
        "\n",
        "1. What is statistics, and why is it important\n",
        "  - Statistics is the science of collecting, analyzing, interpreting, and presenting data.\n",
        "  - Why it’s important:\n",
        "    - It helps us make sense of data, whether it's exam scores, market trends, or sensor readings.\n",
        "    - It supports informed decision-making in fields like business, healthcare, and engineering.\n",
        "    - It reveals patterns, trends, and relationships we might miss at a glance.\n",
        "    - It’s foundational for machine learning and AI—powering everything from recommendations to predictions.\n",
        "   \n",
        "2. What are the two main types of statistics\n",
        "  - The two main types of statistics are:\n",
        "    - Descriptive Statistics\n",
        "    - Inferential Statistics\n",
        "    - Descriptive tells the story, Inferential guesses what happens next.\n",
        "\n",
        "3. What are descriptive statistics\n",
        "  - Descriptive Statistics: It summarizes and describes data. Think: mean, median, mode, standard deviation, charts, etc. It's all about understanding \"what happened\" in a dataset.\n",
        "\n",
        "4. What is inferential statistics\n",
        "  - Inferential Statistics: It helps you make predictions or decisions based on a sample. You draw conclusions about a population using tools like hypothesis testing, confidence intervals, and regression\n",
        "\n",
        "5. What is sampling in statistics\n",
        "  - Sampling is the process of selecting a subset (called a sample) from a larger group (called a population) to analyze and draw conclusions about the whole.\n",
        "  - Why we use it:\n",
        "    - It’s often impractical or impossible to study an entire population.\n",
        "    - It saves time, money, and resources.\n",
        "    - If done correctly, a good sample gives us accurate insights about the population.\n",
        "\n",
        "6. What are the different types of sampling methods\n",
        "  - Probability Sampling (every individual has a known chance of selection)\n",
        "    - Simple Random Sampling: Each individual is chosen purely by chance (like drawing names from a hat).\n",
        "    - Stratified Sampling: Divide the population into groups (strata) and randomly sample from each group.\n",
        "    - Systematic Sampling: Select every kᵗʰ individual from a list (e.g., every 10th customer).\n",
        "    - Cluster Sampling: Randomly select groups (clusters), then sample everyone within those groups.\n",
        "\n",
        "  - Non-Probability Sampling (selection based on factors other than chance)\n",
        "    - Convenience Sampling: Use whoever’s easiest to reach (e.g., surveying people at a mall).\n",
        "    - Judgmental (Purposive) Sampling: Choose based on expert judgment about who should be included.\n",
        "    - Snowball Sampling: Existing participants refer others (common in hard-to-reach populations).\n",
        "    - Quota Sampling: Fill pre-set quotas for different categories (e.g., 50% male, 50% female).\n",
        "\n",
        "7. What is the difference between random and non-random sampling\n",
        "  - The key difference lies in how samples are selected\n",
        "  - Random Sampling\n",
        "    - Every individual has an equal and known chance of being chosen.\n",
        "    - Reduces bias → results are more generalizable.\n",
        "    - Examples: simple random, stratified, cluster sampling\n",
        "    - Use case: Fair lottery system\n",
        "  - Non-Random Sampling\n",
        "    - Selection depends on judgment, convenience, or other non-random factors.\n",
        "    - Faster and easier, but may introduce bias.\n",
        "    - Examples: convenience, snowball, purposive sampling.\n",
        "      Use case: Grabbing whoever's nearby at the mall\n",
        "\n",
        "8. Define and give examples of qualitative and quantitative data\n",
        "  - Qualitative Data: Describes qualities or characteristics — not measurable by numbers.\n",
        "    - Also called: Categorical or non-numeric data\n",
        "    - Examples:\n",
        "    - Colors of cars: red, blue, black\n",
        "    - Animals: penguin, tiger, dolphin\n",
        "    - Customer feedback: \"excellent\", \"okay\", \"poor\"\n",
        "    - Gender, nationality, blood type\n",
        "  - Quantitative Data: Numerical values that represent counts or measurements\n",
        "    - Can be:\n",
        "      - Discrete (countable): Number of students, apples, website visits\n",
        "      - Continuous (measurable): Height in cm, weight in kg, temperature in °C\n",
        "\n",
        "9. What are the different types of data in statistics\n",
        "  1. Quantitative (Numerical) Data: Data that represents amounts or counts.\n",
        "    - Discrete: Countable, no decimals.\n",
        "    Example: number of books, test scores.\n",
        "    - Continuous: Measurable, can have decimals.\n",
        "    Example: height, temperature, salary.\n",
        "\n",
        "  2. Qualitative (Categorical) Data: Data that represents labels or categories.\n",
        "    - Nominal: No inherent order.\n",
        "    Example: colors, gender, brand names.\n",
        "    - Ordinal: Has a clear order or rank.\n",
        "    Example: satisfaction levels, clothing sizes.\n",
        "\n",
        "10. Explain nominal, ordinal, interval, and ratio levels of measurement?\n",
        "    - Nominal: Categories with no order\n",
        "      - Examples: Gender (male/female), Blood type (A, B, AB, O), Car brands\n",
        "      - Math allowed: Only counts and mode\n",
        "    - Ordinal: Categories with order, but no consistent spacing\n",
        "      - Examples: Satisfaction (low, medium, high), Education level\n",
        "      - Math allowed: Median, rank — but not meaningful difference\n",
        "    - Interval: Ordered, evenly spaced values — but no true zero\n",
        "      - Examples: Temperature in °C or °F, IQ scores\n",
        "      - Math allowed: Mean, standard deviation — but ratios don’t make sense\n",
        "      (e.g., 20°C isn’t “twice as hot” as 10°C)\n",
        "    - Ratio: Like interval, but with a true zero\n",
        "      - Examples: Height, weight, age, income\n",
        "      - Math allowed: All operations — including ratios\n",
        "      (e.g., 80kg is twice as heavy as 40kg)\n",
        "\n",
        "11. What is the measure of central tendency\n",
        "  - The measure of central tendency tells us where the \"center\" of a data set lies — the typical or average value that represents the whole group.\n",
        "  eg: Mean, Median and Mode.\n",
        "\n",
        "12. Define mean, median, and mode\n",
        "    - Mean: The arithmetic average of a dataset\n",
        "    Add all values, divide by count\n",
        "    Example: (10 + 20 + 30) / 3 = 20\n",
        "    - Median: The middle value of a dataset\n",
        "    Sort data; pick the middle one\n",
        "    Example: [5, 7, 10] → Median = 7\n",
        "    Example: [5, 7, 8, 10] → Median = 7.5\n",
        "    - Mode: The most frequent value in the dataset\n",
        "    Example: [3, 3, 6, 7, 8] → Mode = 3\n",
        "\n",
        "13. What is the significance of the measure of central tendency\n",
        "  - Measures of central tendency — mean, median, and mode — help us understand the \"typical\" or \"center\" of a dataset. Here's why they're important:\n",
        "    - Significance:\n",
        "      - Summarize data with a single, representative value (instead of looking at all values individually)\n",
        "      - Spot trends or shifts over time e.g., rising average temperature\n",
        "      - Compare groups or distributions e.g., average income by region\n",
        "      - Choose appropriate analysis methods e.g., median is better with skewed or outlier-heavy data\n",
        "      - Support decision-making e.g., marketing, health, education — wherever you need to “know the norm”\n",
        "\n",
        "14. What is variance, and how is it calculated\n",
        "  - Variance measures how spread out the values in a dataset are from the mean, it tells you how much the data varies.\n",
        "    - Formula (for a sample):\n",
        "      [ s^2 = \\frac{1}{n - 1} \\sum (x_i - \\bar{x})^2 ]\n",
        "      Where:\n",
        "      - ( x_i ) = each data point\n",
        "      - ( \\bar{x} ) = sample mean\n",
        "      - ( n ) = number of data points\n",
        "      - ( s^2 ) = sample variance\n",
        "\n",
        "    - Steps to Calculate:\n",
        "      - Find the mean of the data.\n",
        "      - Subtract the mean from each value (get deviations).\n",
        "      - Square each deviation.\n",
        "      - Add them up.\n",
        "      - Divide by ( n - 1 ) (for a sample) or ( n ) (for a population).\n",
        "\n",
        "15. What is skewness in a dataset\n",
        "  - Skewness measures how asymmetrical a dataset is, around its mean — in other words, whether the data leans more to the left or right.\n",
        "  - Types of Skewness:\n",
        "      - Positive Skew (Right-skewed)\n",
        "        - Tail is longer on the right\n",
        "        - Mean > Median > Mode\n",
        "        - Example: income distribution (a few very high earners)\n",
        "      - Negative Skew (Left-skewed)\n",
        "        - Tail is longer on the left\n",
        "        - Mean < Median < Mode\n",
        "        - Example: test scores on an easy exam (most students score high)\n",
        "      - Zero Skew (Symmetrical)\n",
        "        - Data is evenly spread\n",
        "        - Mean = Median = Mode\n",
        "        - Example: ideal bell curve (normal distribution)\n",
        "\n",
        "16. What is standard deviation, and why is it important\n",
        "  - Standard deviation measures how much the values in a dataset deviate from the mean — it tells you how spread out the data is.\n",
        "  - Why It's Important:\n",
        "      - Low standard deviation → values are tightly clustered around the mean\n",
        "      - High standard deviation → values are widely spread out\n",
        "\n",
        "17. Define and explain the term range in statistics\n",
        "  - Range in statistics is the simplest way to measure how spread out a dataset is.\n",
        "  - The range is the difference between the highest and lowest values in a dataset.\n",
        "  - ```Range = Maximum value - Minimum value```\n",
        "\n",
        "18. What is the difference between variance and standard deviation\n",
        "  - Variance\n",
        "      - Measures the average squared deviation from the mean.\n",
        "      - Formula:```[ \\text{Variance} = \\frac{1}{n - 1} \\sum (x_i - \\bar{x})^2 ]```\n",
        "      - Unit: Squared (e.g., cm², kg²) — which can be hard to interpre and compare.\n",
        "  - Standard Deviation\n",
        "      - It’s simply the square root of variance.\n",
        "      - Brings the spread back to the original units (e.g., cm, kg).\n",
        "      - Easier to interpret and compare.\n",
        "\n",
        "19. What does it mean if a dataset is positively or negatively skewed\n",
        "  - Skewness tells us how asymmetrical a dataset is.\n",
        "  - Positively Skewed (Right-Skewed)\n",
        "      - The tail stretches to the right.\n",
        "      - Most values are low, with a few high outliers.\n",
        "      - Mean > Median > Mode\n",
        "      - Example: Income — most people earn modestly, but a few earn a lot.\n",
        "  - Negatively Skewed (Left-Skewed)\n",
        "      - The tail stretches to the left.\n",
        "      - Most values are high, with a few low outliers.\n",
        "      - Mean < Median < Mode\n",
        "      - Example: Test scores on an easy exam — most students score high, a few score low.\n",
        "  - Skewness affects which measure of central tendency is most reliable and whether you need to transform the data before modeling.\n",
        "\n",
        "20. Define and explain kurtosis\n",
        "  - Kurtosis measures the \"tailedness\" or peakedness of a distribution — basically, how heavy or light the tails are, compared to a normal distribution. Helps detect outliers and extreme values\n",
        "\n",
        "  - Types of Kurtosis:\n",
        "      - Mesokurtic\n",
        "          - Normal distribution\n",
        "          - Moderate tails\n",
        "          - Kurtosis ≈ 3\n",
        "      - Leptokurtic\n",
        "          - High peak, fat tails\n",
        "          - More outliers than normal\n",
        "          - Kurtosis > 3\n",
        "      - Platykurtic\n",
        "          - Flat peak, thin tails\n",
        "          - Fewer outliers\n",
        "          - Kurtosis < 3\n",
        "\n",
        "21. What is the purpose of covariance\n",
        "  - Covariance helps us understand how two variables change together — whether they move in the same direction, opposite directions, or independently.\n",
        "  - Purpose of Covariance:\n",
        "    - Detects Direction of Relationship\n",
        "        - Positive covariance: both variables increase or decrease together\n",
        "        - Negative covariance: one increases while the other decreases\n",
        "    - Foundation for Correlation\n",
        "        - Correlation is a standardized version of covariance (unit-free)\n",
        "    - Used in Finance & ML\n",
        "        - Portfolio risk analysis, PCA (Principal Component Analysis), and more\n",
        "\n",
        "22. What does correlation measure in statistics\n",
        "  - Correlation measures the strength and direction of a relationship between two variables — it tells you how closely they move together.\n",
        "      - Positive correlation: As one variable increases, the other tends to increase\n",
        "      (e.g., height and weight)\n",
        "      - Negative correlation: As one increases, the other tends to decrease\n",
        "      (e.g., exercise time and stress level)\n",
        "      - Zero correlation: No consistent pattern between the two\n",
        "      (e.g., shoe size and intelligence)\n",
        "   - Measured by the correlation coefficient (r):\n",
        "      - Ranges from -1 to +1\n",
        "      - +1 = perfect positive relationship\n",
        "      - -1 = perfect negative relationship\n",
        "      - 0 = no relationship\n",
        "\n",
        "23. What is the difference between covariance and correlation\n",
        "\n",
        "| |Covariance|Correlation|\n",
        "|:---------:|:---------:|:---------:|\n",
        "|Tells you | Whether two variables move together (direction only) | Both the direction and strength of the relationship |\n",
        "|Value range| From –∞ to +∞| Always between -1 and +1|\n",
        "|Units| Has units (depends on the variables)|Unitless (standardized)|\n",
        "|Scale-sensitive| Affected by the magnitude of the data|Scale-invariant: Not affected by variable scale|\n",
        "|Interpretation| Harder to compare across datasets|Easier to compare and interpret|\n",
        "\n",
        "\n",
        "24. What are some real-world applications of statistics?\n",
        "  - Statistics is everywhere, Sam — quietly powering decisions, predictions, and discoveries across nearly every field. Here are some real-world applications that show just how essential it is:\n",
        "    - Healthcare\n",
        "      - Designing clinical trials for new drugs\n",
        "      - Tracking disease spread in epidemiology\n",
        "      - Analyzing patient data to improve treatments\n",
        "      Statistics is everywhere, Sam — quietly powering decisions, predictions, and discoveries across nearly every field. Here are some real-world applications that show just how essential it is:\n",
        "    - Healthcare\n",
        "      - Designing clinical trials for new drugs\n",
        "      - Tracking disease spread in epidemiology\n",
        "      - Analyzing patient data to improve treatments\n",
        "    - Business & Marketing\n",
        "      - Understanding customer behavior\n",
        "      - Forecasting sales and demand\n",
        "      - A/B testing for ad campaigns and product features\n",
        "    - Finance\n",
        "      - Assessing investment risk and portfolio performance\n",
        "      - Pricing insurance using actuarial models\n",
        "      - Detecting fraud through anomaly detection\n",
        "    - Weather Forecasting\n",
        "      - Predicting rain, storms, or temperature using probability models\n",
        "      - Analyzing climate trends over time\n",
        "    - Transportation\n",
        "      - Optimizing traffic flow and public transit routes\n",
        "      - Planning infrastructure using traffic pattern data\n",
        "    - Education\n",
        "      - Evaluating student performance\n",
        "      - Designing fair standardized tests\n",
        "      - Measuring teaching effectiveness\n",
        "    - Science & Research\n",
        "      - Testing hypotheses in experiments\n",
        "      - Modeling natural phenomena\n",
        "      - Analyzing survey or observational data\n",
        "    - Government & Policy\n",
        "      - Conducting censuses and public opinion polls\n",
        "      - Evaluating policy impact\n",
        "      - Allocating resources based on population needs\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5gjKr188jIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions\n",
        "---\n"
      ],
      "metadata": {
        "id": "1kXex3dE6z-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADijjVCQnnz1",
        "outputId": "4eafb08a-4583-4aba-ad71-da1b5fa56258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 13\n",
            "Median: 8\n",
            "Mode: 4\n"
          ]
        }
      ],
      "source": [
        " # 1. How do you calculate the mean, median, and mode of a dataset\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "\n",
        "data = [2,3,4,4,5,8,9,12,40,41,15]\n",
        "print(f\"Mean: {stat.mean(data)}\")\n",
        "print(f\"Median: {stat.median(data)}\")\n",
        "print(f\"Mode: {stat.mode(data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write a Python program to compute the variance and standard deviation of a dataset\n",
        "\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "\n",
        "data = [2,3,4,4,5,8,9,12,40,41,15]\n",
        "print('Variance:', np.var(data))\n",
        "print('Standard Deviation:',np.std(data))"
      ],
      "metadata": {
        "id": "CAek7x7Mn8Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a dataset and classify it into nominal, ordinal, interval, and ratio types\n",
        "\n",
        "import pandas as pd\n",
        "dataset = {\n",
        "    \"Person_ID\": [101, 102, 103, 104],\n",
        "    \"Gender\": [\"Male\", \"Female\", \"Other\", \"Male\"],\n",
        "    \"Education_Level\": [\"Bachelor's\", \"Master's\", \"High School\", \"PhD\"],\n",
        "    \"Temperature_C\": [36, 37, 36.5, 35],\n",
        "    \"Age_Years\": [25, 30, 22, 45],\n",
        "    \"Income_INR\": [35000, 50000, 22500, 75000]\n",
        "}\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "print(df)\n",
        "\n",
        "classification = {'colname':['Person ID', 'Gender','Education Level','Temperature', 'Age(Yrs)','Income($)'],\n",
        "                  'DataType':['Nominal','Nominal','Ordinal','Interval','Ratio', 'Ratio'],\n",
        "                  'Reason':['Just labels to identify people, - no mathematical value.','Categories without order',\"There is a meaningful order, but differences between categories aren't consistent. \",'Numeric, equal spacing but no true zero','numeric, equal spacing and zero means absence of age','Has a true zero and supports all arithmetic operations']\n",
        "                  }\n",
        "classdf = pd.DataFrame(classification)\n",
        "classdf\n",
        "\n"
      ],
      "metadata": {
        "id": "PJctPlDZoA51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Implement sampling techniques like random sampling and stratified sampling\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Your dataset\n",
        "dataset = {\n",
        "    \"Person_ID\": [101, 102, 103, 104],\n",
        "    \"Gender\": [\"Male\", \"Female\", \"Other\", \"Male\"],\n",
        "    \"Education_Level\": [\"Bachelor's\", \"Master's\", \"High School\", \"PhD\"],\n",
        "    \"Temperature_C\": [36, 37, 36.5, 35],\n",
        "    \"Age_Years\": [25, 30, 22, 45],\n",
        "    \"Income_INR\": [35000, 50000, 22500, 75000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "# Randomly sample 2 rows\n",
        "random_sample = df.sample(n=2, random_state=42)\n",
        "print(\"Random Sample:\\n\", random_sample)\n",
        "\n",
        "# Stratified sample based on 'Gender'\n",
        "stratified_sample = df.groupby('Gender', group_keys=False).apply(lambda x: x.sample(n=1, random_state=42))\n",
        "print(\"Stratified Sample by Gender:\\n\", stratified_sample)"
      ],
      "metadata": {
        "id": "CW7hFeWwoJEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python function to calculate the range of a dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Your dataset\n",
        "dataset = {\n",
        "    \"Person_ID\": [101, 102, 103, 104],\n",
        "    \"Gender\": [\"Male\", \"Female\", \"Other\", \"Male\"],\n",
        "    \"Education_Level\": [\"Bachelor's\", \"Master's\", \"High School\", \"PhD\"],\n",
        "    \"Temperature_C\": [36, 37, 36.5, 35],\n",
        "    \"Age_Years\": [25, 30, 22, 45],\n",
        "    \"Income_INR\": [35000, 50000, 22500, 75000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "print (\"Range: \" , max(df['Income_INR']) - min(df['Income_INR']))"
      ],
      "metadata": {
        "id": "8NUDGCVboucc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 6. Create a dataset and plot its histogram to visualize skewness\n",
        " import pandas as pd\n",
        " import seaborn as sns\n",
        "from scipy.stats import skew\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Symmetric\": [10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
        "    \"Positively_Skewed\": [5, 6, 7, 8, 9, 10, 12, 30, 80],  # Stronger right tail\n",
        "     \"Negatively_Skewed\": [90, 88, 85, 83, 80, 78, 75, 40, 10]  # Stronger left tail\n",
        "\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Symmetric skew:\", skew(df[\"Symmetric\"]))\n",
        "print(\"Positive skew:\", skew(df[\"Positively_Skewed\"]))\n",
        "print(\"Negative skew:\", skew(df[\"Negatively_Skewed\"]))\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize = (15,5), sharey=True)\n",
        "\n",
        "# Symmetric Distribution\n",
        "sns.histplot(df[\"Symmetric\"], kde=True, bins=5, ax=axes[0], color=\"skyblue\", edgecolor=\"black\")\n",
        "axes[0].set_title(\"Symmetric Distribution\")\n",
        "\n",
        "# Positively Skewed\n",
        "sns.histplot(df[\"Positively_Skewed\"], bins=10, kde=True,ax=axes[1], color=\"lightgreen\", edgecolor=\"black\")\n",
        "axes[1].set_title(\"Positively Skewed\")\n",
        "\n",
        "# Negatively Skewed\n",
        "sns.histplot(df[\"Negatively_Skewed\"], bins=10, kde=True, ax=axes[2], color=\"salmon\", edgecolor=\"black\")\n",
        "axes[2].set_title(\"Negatively Skewed\")\n",
        "\n",
        "plt.suptitle(\"Histogram with KDE for Different Skewness Types\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D89Ghbnno3Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 7. Calculate skewness and kurtosis of a dataset using Python libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "data = {\n",
        "    \"Symmetric\": [10, 12, 8, 10, 14, 10, 8, 12, 10],\n",
        "    \"Positively_Skewed\": [5, 6, 7, 8, 9, 10, 12, 100, 120],  # Stronger right tail\n",
        "     \"Negatively_Skewed\": [85, 83, 78, 76, 74, 70, 68, 65, 60]  # Stronger left tail\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#calculate Skewness\n",
        "posskewness = skew(df['Positively_Skewed'],bias=False)\n",
        "negskewness = skew(df['Negatively_Skewed'],bias=False)\n",
        "\n",
        "#Calculate Kurtosis\n",
        "symkurt = kurtosis(df['Symmetric'],bias=False)\n",
        "poskurt = kurtosis(df['Positively_Skewed'], bias=False)\n",
        "negkurt = kurtosis(df['Negatively_Skewed'], bias=False)\n",
        "\n",
        "print(f\"Kurtosis for Symmetric is almost Mesokurtic : {symkurt:.3f}\")\n",
        "\n",
        "print(f\"Positively Skewed: {posskewness:.3f} & Leptokurtic Distribution: {poskurt:.3f} \")\n",
        "\n",
        "print(f\"Negatively Skewed: {negskewness:.3f} & Platykurtic Distribution: {negkurt:.3f} \")\n",
        "\n"
      ],
      "metadata": {
        "id": "XhM4bnsxo8PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 8. Generate a dataset and demonstrate positive and negative skewness\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Positively skewed: exponential distribution\n",
        "positive_skew = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Negatively skewed: mirror the exponential distribution\n",
        "negative_skew = -np.random.exponential(scale=2, size=1000) + 10\n",
        "\n",
        "# Combine into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Positively_Skewed\": positive_skew,\n",
        "    \"Negatively_Skewed\": negative_skew\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
        "\n",
        "# Positive skew\n",
        "sns.histplot(df[\"Positively_Skewed\"], kde=True, bins=30, ax=axes[0], color=\"skyblue\", edgecolor=\"black\")\n",
        "axes[0].set_title(\"Positively Skewed\")\n",
        "\n",
        "# Negative skew\n",
        "sns.histplot(df[\"Negatively_Skewed\"], kde=True, bins=30, ax=axes[1], color=\"salmon\", edgecolor=\"black\")\n",
        "axes[1].set_title(\"Negatively Skewed\")\n",
        "\n",
        "plt.suptitle(\"Demonstrating Positive and Negative Skewness\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rtww3Fxio8EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python script to calculate covariance between two datasets\n",
        "import statistics as stat\n",
        "\n",
        "data = {\n",
        "    \"Symmetric\": [10, 12, 8, 10, 14, 10, 8, 12, 10],\n",
        "    \"Positively_Skewed\": [5, 6, 7, 8, 9, 10, 12, 100, 120],  # Stronger right tail\n",
        "     \"Negatively_Skewed\": [85, 83, 78, 76, 74, 70, 68, 65, 60]  # Stronger left tail\n",
        "}\n",
        "print(f\"Covariance between Symmetric and Positively skewed: {stat.covariance(data['Symmetric'],data['Positively_Skewed'])}\")\n",
        "print(f\"Covariance between Positively and Negatively skewed: {stat.covariance(data['Positively_Skewed'],data['Negatively_Skewed'])}\")\n"
      ],
      "metadata": {
        "id": "GPlMvYmeo75k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Write a Python script to calculate the correlation coefficient between two datasets\n",
        "import statistics as stat\n",
        "\n",
        "data = {\n",
        "    \"Symmetric\": [10, 12, 8, 10, 14, 10, 8, 12, 10],\n",
        "    \"Positively_Skewed\": [5, 6, 7, 8, 9, 10, 12, 100, 120],  # Stronger right tail\n",
        "     \"Negatively_Skewed\": [85, 83, 78, 76, 74, 70, 68, 65, 60]  # Stronger left tail\n",
        "}\n",
        "\n",
        "print(f\"Correlation between Symmetric and Positively skewed: {stat.correlation(data['Symmetric'],data['Positively_Skewed'])}\")\n",
        "print(f\"Correlation between Positively and Negatively skewed: {stat.correlation(data['Positively_Skewed'],data['Negatively_Skewed'])}\")"
      ],
      "metadata": {
        "id": "gy0QXRe0o7vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 11. Create a scatter plot to visualize the relationship between two variables\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    \"Age\": [22,22, 25, 25, 30, 35,35, 40, 45, 50, 50, 55, 55, 60,60, 65, 65],\n",
        "    \"Income\": [22000,25000, 28000,30000, 35000, 33000,40000,35000, 45000, 48000,53000, 50000,52000, 52000,55000, 55000, 54000],\n",
        "    \"Gender\": ['M','F','M','F','M','F','M','F','M','M','M','F','M','F','M','F','M']\n",
        "}\n",
        "print(len(data['Age']))\n",
        "print(len(data['Income']))\n",
        "print(len(data['Gender']))\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "sns.scatterplot(x=\"Age\",y=\"Income\", data=df, color=\"teal\",s=100, edgecolor=\"black\", hue=\"Gender\")\n",
        "plt.title(\"Scatter Plot: Age vs Income of a person, Gender-wise\")\n",
        "plt.xlabel(\"Age(years)\")\n",
        "plt.ylabel(\"Income (₹)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nuykjTeto7mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 12. Implement and compare simple random sampling and systematic sampling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#sample population of 100 items\n",
        "np.random.seed(42)\n",
        "pop_sample = pd.DataFrame({\n",
        "    \"ID\":range(1,101),\n",
        "    \"Score\":np.random.randint(50,100, size=100)\n",
        "})"
      ],
      "metadata": {
        "id": "I0CDvB-Po7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 13 Calculate the mean, median, and mode of grouped data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statistics as stat\n",
        "import math\n",
        "\n",
        "data = {\n",
        "    \"Age\": [22,22, 25, 25, 30, 35,35, 40, 40, 50, 50, 55, 55, 60,60, 65, 65],\n",
        "    \"Income\": [22000,25000, 28000,30000, 35000, 33000,40000,35000, 45000, 48000,53000, 50000,52000, 52000,55000, 55000, 54000],\n",
        "    \"Gender\": ['M','F','M','F','M','F','M','F','F','F','M','M','F','F','M','M','M']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print('Mean:', df.groupby('Gender').mean().round(2))\n",
        "print('Median:',df.groupby('Gender').median().round(2))\n",
        "# print(df.groupby('Gender').mode())\n",
        "# stat.mode(df.groupby('Gender'))\n",
        "mode_Age = df.groupby('Gender')['Age'].agg(lambda x:pd.Series.mode(x))\n",
        "mode_Income = df.groupby('Gender')['Income'].agg(lambda y:pd.Series.mode(y))\n",
        "\n",
        "print(\"Mode of Age:\\n\",mode_Age)\n",
        "print(\"Mode of Income:\\n\",mode_Income)"
      ],
      "metadata": {
        "id": "_N6hrInpo7VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 14. Simulate data using Python and calculate its central tendency and dispersion.\n",
        "import pandas as pd\n",
        "import statistics as stat\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "pop_sample = pd.DataFrame({\n",
        "    \"ID\":range(1,101),\n",
        "    \"Score\":np.random.randint(50,100, size=100)\n",
        "})\n",
        "print(\"  Measures of Central Tendency\\n \", '='*30)\n",
        "\n",
        "print(f\" Mean: {stat.mean(pop_sample['Score']):.2f}\")\n",
        "print(f\" Median: {stat.median(pop_sample['Score']):.2f}\")\n",
        "print(f\" Mode: {stat.mode(pop_sample['Score']):.2f}\")\n",
        "print(\"\\n  Measures of Dispersion\\n\", '='*30)\n",
        "print(f\" Sample Variance: {stat.variance(pop_sample['Score']):.2f}\")\n",
        "print(f\" Population Variance: {stat.pvariance(pop_sample['Score']):.2f}\")\n",
        "print(f\" Standard Deviation of Sample: {stat.stdev(pop_sample['Score']):.2f}\")\n",
        "print(f\" Standard Deviation of Population: {stat.pstdev(pop_sample['Score']):.2f}\")\n",
        "print(f\" Range: {pop_sample['Score'].max() - pop_sample['Score'].min()}\")\n",
        "\n",
        "sns.histplot(pop_sample[\"Score\"], kde=True, bins=20, color=\"salmon\", edgecolor=\"black\")\n",
        "plt.title(\"Simulated Score Distribution\")\n",
        "plt.xlabel(\"Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CaHkYfYQo7L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 15 Use NumPy or pandas to summarize a dataset’s descriptive statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = {\n",
        "  \"Age\": [22,22, 25, 25, 30, 35,35, 40, 40, 50, 50, 55, 55, 60,60, 65, 65],\n",
        "  \"Income\": [22000,25000, 28000,30000, 35000, 33000,40000,35000, 45000, 48000,53000, 50000,52000, 52000,55000, 55000, 54000],\n",
        "  \"Gender\": ['M','F','M','F','M','F','M','F','F','F','M','M','F','F','M','M','M']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.groupby('Gender').describe())  #grouped by Gender..\n",
        "df.describe() #without any grouping.\n"
      ],
      "metadata": {
        "id": "tpLUEEtfo7EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Plot a boxplot to understand the spread and identify outliers\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.DataFrame({\n",
        "    \"Score\": [55, 60, 62, 65, 67, 68, 70, 72, 75, 78, 80, 82, 85, 88, 90, 92, 95, 98, 100, 150]\n",
        "})\n",
        "\n",
        "# Calculate quartiles\n",
        "\n",
        "q1 = df[\"Score\"].quantile(0.25)\n",
        "q2 = df[\"Score\"].median()\n",
        "q3 = df[\"Score\"].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower_fence = q1 - 1.5 * iqr\n",
        "upper_fence = q3 + 1.5 * iqr\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "ax = sns.boxplot(y=\"Score\", data=df, color=\"skyblue\", width=0.3)\n",
        "\n",
        "for label, value in [\n",
        "    (\"Lower Fence\", lower_fence),\n",
        "    (\"Q1\", q1),\n",
        "    (\"Q2 (Median)\", q2),\n",
        "    (\"Q3\", q3),\n",
        "    (\"Upper Fence\", upper_fence)\n",
        "]:\n",
        "    plt.annotate(f\"{label}: {value:.1f}\",\n",
        "                 xy=(0, value),\n",
        "                 xytext=(0.2, value),\n",
        "                 textcoords='data',\n",
        "                 arrowprops=dict(arrowstyle=\"->\", color=\"black\"),\n",
        "                 fontsize=9,\n",
        "                 color=\"darkblue\",\n",
        "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "\n",
        "plt.suptitle(\"Boxplot of Scores with Outlier Detection\")\n",
        "plt.title(f\"IQR: {iqr}, Upper Fence: {upper_fence}, Lower Fence: {lower_fence}\")\n",
        "plt.ylabel('Score')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.annotate('test',(0,0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lLbECumio68Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Calculate the interquartile range (IQR) of a dataset\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    \"Score\": [55, 60, 62, 65, 67, 68, 70, 72, 75, 78, 80, 82, 85, 88, 90, 92, 95, 98, 100, 150]\n",
        "})\n",
        "\n",
        "# Calculate quartiles\n",
        "\n",
        "q1 = df[\"Score\"].quantile(0.25)\n",
        "q2 = df[\"Score\"].median()\n",
        "q3 = df[\"Score\"].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "print(f\"Interquartile range (IQR) is :{iqr} \")"
      ],
      "metadata": {
        "id": "dJk57FhPo60I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Implement Z-score normalization and explain its significance\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({\n",
        "    'Height_cm': [160, 165, 170, 175, 180],\n",
        "    'Weight_kg': [55, 60, 65, 70, 120]  # Notice the outlier\n",
        "})\n",
        "\n",
        "# Apply Z-score normalization\n",
        "df_z = df.apply(zscore)\n",
        "\n",
        "print(df_z)\n",
        "# print(f\"Mean is {df['Score'].mean()} due to the outlier 200.\")\n",
        "\n",
        "print('''The Z-Score tells us how many standard deviations a value is from the mean of dataset. It's super useful for spotting outliers or standardizing data.\n",
        "\n",
        "Z-score normalization (also called standardization) transforms the data so that:\n",
        "- The mean becomes 0\n",
        "- The standard deviation becomes 1\n",
        "\n",
        "Why It’s Important\n",
        "- Puts features on the same scale\n",
        "Especially useful when features have different units (e.g., cm vs. kg).\n",
        "- Essential for distance-based algorithms\n",
        "Algorithms like k-NN, SVM, and K-Means rely on distance — unscaled features can skew results.\n",
        "- Helps detect outliers\n",
        "Z-scores beyond ±3 often indicate anomalies.\n",
        "- Improves model convergence\n",
        "Gradient-based models (like logistic regression or neural nets) train faster and more reliably.\n",
        "\n",
        "''')\n"
      ],
      "metadata": {
        "id": "GTf6tJnKo6qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Compare two datasets using their standard deviations\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({\n",
        "    'Height_cm': [163, 165, 167, 169, 170],\n",
        "    'Weight_kg': [55, 60, 65, 70, 120]  # Notice the outlier\n",
        "})\n",
        "\n",
        "print(f\"Lower Standard Deviation of Height: {df['Height_cm'].std()} implies that values are more clustered around the mean. {df['Height_cm'].mean()}\")\n",
        "print(f\"Higher Standard Deviation of Weight: {df['Weight_kg'].std()} imlies that the values are more spread out in the distribution. from the mean {df['Weight_kg'].mean()}\")\n"
      ],
      "metadata": {
        "id": "UWya6-vMo6iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Write a Python program to visualize covariance using a heatmap\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# Sample dataset\n",
        "# Load dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "\n",
        "cov_matrix = df.cov(numeric_only=True)\n",
        "\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cov_matrix, annot=True, cmap=\"YlOrBr\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Covariance Matrix Heatmap – tips\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "u6NdpUPSo6ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Use seaborn to create a correlation matrix for a dataset\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "# Sample dataset\n",
        "# Load dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "\n",
        "corr = df.corr(numeric_only=True)\n",
        "\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(corr, annot=True, cmap=\"YlOrBr\", fmt=\".2f\", linewidths=0.5)\n",
        "sns.pairplot(df)\n",
        "plt.title(\"Correlation Matrix Heatmap – Tips\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "opVaxTSBo6P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Generate a dataset and implement both variance and standard deviation computations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statistics as stat\n",
        "\n",
        "np.random.seed(42)\n",
        "temps = np.random.normal(loc=30, scale=3, size=100)  # Mean=30°C, SD=3°C\n",
        "df = pd.DataFrame({\"Temperature\": temps})\n",
        "\n",
        "# Using pandas\n",
        "variance = df[\"Temperature\"].var()\n",
        "std_dev = df[\"Temperature\"].std()\n",
        "\n",
        "print(f\"Sample Variance: {variance:.2f}\")\n",
        "print(f\"Population Variance: {stat.pvariance(df['Temperature']):.2f}\")\n",
        "print(f\"Sample Standard Deviation: {std_dev:.2f}\")\n",
        "print(f\"Population Standard Deviation: {stat.pstdev(df['Temperature']):.2f}\")\n"
      ],
      "metadata": {
        "id": "rp7UobXFo6Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Load a clean dataset\n",
        "df = sns.load_dataset(\"mpg\").dropna()\n",
        "data = df[\"mpg\"]  # Miles per gallon\n",
        "\n",
        "# Calculate skewness and kurtosis\n",
        "skew_val = skew(data)\n",
        "kurt_val = kurtosis(data)\n",
        "\n",
        "# Plot histogram with KDE\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data, kde=True, bins=30, color=\"mediumseagreen\", edgecolor=\"black\")\n",
        "plt.title(f\"Distribution of MPG\\nSkewness: {skew_val:.2f} | Kurtosis: {kurt_val:.2f}\")\n",
        "plt.xlabel(\"Miles per Gallon (mpg)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FRdaTZ95o578"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Implement the Pearson and Spearman correlation coefficients for a dataset.\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset and drop missing values\n",
        "df = sns.load_dataset(\"mpg\").dropna()\n",
        "\n",
        "# Select numeric features\n",
        "features = ['mpg', 'horsepower', 'weight', 'acceleration']\n",
        "data = df[features]\n",
        "\n",
        "pearson_corr = data.corr(method='pearson')\n",
        "print(\"Pearson Correlation Matrix:\\n\", pearson_corr)\n",
        "print('''\n",
        "- Measures linear relationships.\n",
        "- Sensitive to outliers and assumes normality.\\n''')\n",
        "\n",
        "spearman_corr = data.corr(method='spearman')\n",
        "print(\"Spearman Correlation Matrix:\\n\", spearman_corr)\n",
        "print('''\n",
        "- Measures monotonic relationships (not necessarily linear).\n",
        "- Based on rankings, so it's more robust to outliers and skewed data.\\n''')\n"
      ],
      "metadata": {
        "id": "12H45lMco5vJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}